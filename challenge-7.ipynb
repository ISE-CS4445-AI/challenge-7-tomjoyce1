{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/{reponame}/blob/main/challenge-7.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSNohoRf9Wum"
      },
      "source": [
        "# Challenge #7: Interpretability and explainable ML\n",
        "\n",
        "In this assignment, you will explore explainability using LIME on image classification. Your tasks are:\n",
        "\n",
        "1. **get_lime_explanation: (3 points)**  \n",
        "   Given a pretrained image classifier and an input image, generate a LIME explanation object.\n",
        "\n",
        "2. **display_lime_explanation: (1 point)**  \n",
        "   From the explanation object, extract and return a visualization (image and mask overlay) that highlights important superpixels.\n",
        "\n",
        "3. **extract_feature_importance: (1 point)**  \n",
        "   Extract a list of important feature (superpixel) contributions from the explanation object, sorted by importance.\n",
        "\n",
        "4. **Task 4:** Apply a pretrained ResNet model on an input image and use LIME to generate and display explanations for the top 5 predicted classes.\n",
        "\n",
        "After coding, answer three brief reflection questions on explainability methods.\n",
        "\n",
        "*Total points: 9 (6 points for code tasks and 3 points for reflection questions).*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Background on LIME\n",
        "\n",
        "LIME (Local Interpretable Model-agnostic Explanations) is a popular method for explaining predictions of any classifier. For image classification, LIME works by:\n",
        "- Perturbing the input image by turning superpixels on/off.\n",
        "- Evaluating how these perturbations affect the prediction.\n",
        "- Fitting a local, interpretable linear model to approximate the classifier's behavior near the instance.\n",
        "\n",
        "The result is an explanation object that can produce:\n",
        "- A list of feature contributions.\n",
        "- A visualization (image with a mask overlay) highlighting which superpixels had the greatest influence on the prediction.\n",
        "\n",
        "**Additional resources:**  \n",
        "[Official LIME blog post](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)  \n",
        "[Tutorial notebooks on their official GitHub repository](https://github.com/marcotcr/lime/tree/master/doc/notebooks)  \n",
        "[General article reading about explainable machine learning | Medium](https://medium.com/michelle-and-ryan-explain-ml/explainable-and-interpretable-machine-learning-7e7c28bba4f2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UM1fVyy9Wun"
      },
      "source": [
        "## Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfptRzGQ9Wuo"
      },
      "outputs": [],
      "source": [
        "from lime import lime_image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGhzcybk9Wuo"
      },
      "source": [
        "## Task 1: Get LIME Explanation <font color='green'>(3 points)</font>\n",
        "\n",
        "Generate and return a LIME explanation object for the given image and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNF9J7iy9Wuo"
      },
      "outputs": [],
      "source": [
        "def get_lime_explanation(model: torch.nn.Module, image: np.ndarray, top_labels: int = 5, num_samples: int = 1000):\n",
        "    \"\"\"\n",
        "    Generate and return a LIME explanation object for the given image and model.\n",
        "\n",
        "    Parameters:\n",
        "        model (torch.nn.Module): A pretrained image classification model.\n",
        "        image (np.ndarray): Input image in numpy array format (H x W x C).\n",
        "        top_labels (int): Number of top labels to consider.\n",
        "        num_samples (int): Number of perturbed samples to generate.\n",
        "\n",
        "    Returns:\n",
        "        explanation: A LIME explanation object (as returned by lime_image.LimeImageExplainer.explain_instance).\n",
        "    \"\"\"\n",
        "    # TODO: Create an instance of LimeImageExplainer.\n",
        "    explainer = None  # Replace with your code\n",
        "    \n",
        "    # TODO: Define a prediction function that accepts a batch of images as numpy arrays and returns prediction probabilities.\n",
        "    def predict(images):\n",
        "        # Convert images to torch tensors, preprocess them, and obtain predictions.\n",
        "        # TODO: Implement the necessary transformation and model inference.\n",
        "        return None  # Replace with your code.\n",
        "    \n",
        "    # TODO: Use the explainer to generate an explanation for the image.\n",
        "    explanation = None  # Replace with your code.\n",
        "    \n",
        "    return explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJQ2coP99Wuo"
      },
      "source": [
        "## Task 2: Display LIME Explanation <font color='green'>(1 point)</font>\n",
        "\n",
        "Implement a function that extracts and returns the visualization of the LIME explanation. This function should use the explanation object's method (such as `get_image_and_mask`) to generate an image with an overlay mask that highlights the most important superpixels.\n",
        "\n",
        "The output should be a tuple: (explanation_image, mask), which you can then display using matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4db54aV9Wup"
      },
      "outputs": [],
      "source": [
        "# Utility function to visualise the LIME explanation\n",
        "def visualiseExplanation(explanation_image, mask):\n",
        "    # show the image boundary\n",
        "    img_boundry = mark_boundaries(explanation_image/255.0, mask)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img_boundry)\n",
        "\n",
        "def display_lime_explanation(explanation, image: np.ndarray, positive_only: bool = True, num_features: int = 5):\n",
        "    \"\"\"\n",
        "    From the LIME explanation object, generate and return the visualization image and mask overlay.\n",
        "\n",
        "    Parameters:\n",
        "        explanation: The LIME explanation object.\n",
        "        image (np.ndarray): The original image (H x W x C).\n",
        "        positive_only (bool): Whether to show only features that positively influence the prediction.\n",
        "        num_features (int): Number of superpixels to display.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (explanation_image, mask) as produced by explanation.get_image_and_mask.\n",
        "    \"\"\"\n",
        "    # TODO: Call explanation.get_image_and_mask with appropriate parameters.\n",
        "    explanation_image, mask = None, None  # Replace with your code.\n",
        "    \n",
        "    return explanation_image, mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Extract Feature Importance <font color='green'>(1 point)</font>\n",
        "\n",
        "Implement a function that extracts a sorted list of feature (superpixel) contributions from the LIME explanation object. The function should return a list of tuples (feature_index, importance) sorted in descending order by importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4_wowyh9Wup"
      },
      "outputs": [],
      "source": [
        "def extract_feature_importance(explanation) -> list:\n",
        "    \"\"\"\n",
        "    Extract and return a sorted list of feature contributions from the LIME explanation object.\n",
        "\n",
        "    Returns:\n",
        "        List[tuple]: Each tuple contains (feature_index, importance) sorted by importance (descending).\n",
        "    \"\"\"\n",
        "    # TODO: Process the output to return a sorted list of tuples.\n",
        "    feature_importances = None  # Replace with your code.\n",
        "    \n",
        "    return feature_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Top 5 explanations from a pretrained ResNet model <font color='green'>(2 points)</font>\n",
        "\n",
        "Use a pretrained ResNet model to predict the image classes and generate LIME explanations for the top 5 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download ImageNet class label mappings\n",
        "!wget https://github.com/marcotcr/lime/blob/master/doc/notebooks/data/imagenet_class_index.json?raw=true -O imagenet_class_index.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import cv2\n",
        "\n",
        "def get_resnet_lime_explanations(image: np.ndarray):\n",
        "    \"\"\"\n",
        "    Use a pretrained ResNet model to predict the image classes and generate LIME explanations for the top 5 classes.\n",
        "    \n",
        "    This function should:\n",
        "      1. Load a pretrained ResNet (e.g., ResNet18) from torchvision.\n",
        "      2. Apply necessary preprocessing to the image.\n",
        "      3. Obtain predictions and determine the top 5 classes.\n",
        "      4. For each of the top 5 classes, generate a LIME explanation using get_lime_explanation().\n",
        "      5. Return a dictionary mapping each top class label to its corresponding explanation visualization (image and mask).\n",
        "    \n",
        "    Boilerplate (e.g., label list) is provided below.\n",
        "    \n",
        "    Returns:\n",
        "        dict: {class_label: (explanation_image, mask), ...} for top 5 classes.\n",
        "    \"\"\"\n",
        "    # Predefined label list for demonstration (first 5 ImageNet classes).\n",
        "    imagenet_labels = json.load(open(\"imagenet_class_index.json\"))\n",
        "    imagenet_labels = {int(key): value[1] for key, value in imagenet_labels.items()}\n",
        "    \n",
        "    # TODO: Load a pretrained ResNet18 model and set it to evaluation mode.\n",
        "    model = None\n",
        "    model.eval()\n",
        "    \n",
        "    # TODO: Generate LIME explanation for the image with top_labels=5.\n",
        "    explanation = None  # Replace with your code.\n",
        "    \n",
        "    explanations = {}\n",
        "\n",
        "    # TODO: Extract the top 5 labels from the explanation.\n",
        "    top5_labels = None # Replace with your code.\n",
        "    for label in top5_labels:\n",
        "        class_name = imagenet_labels.get(label, str(label))\n",
        "        # TODO: Extract visualization (image and mask).\n",
        "        expl_img, mask = None, None  # Replace with your code.\n",
        "        explanations[class_name] = (expl_img, mask)\n",
        "    \n",
        "    return explanations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection Questions (answer in brief)  <font color='green'>(1 point each)</font>\n",
        "\n",
        "**Question 1:**  \n",
        "What are the main advantages of using LIME for explaining image classification models?  \n",
        "*Your Answer:*  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> *(Type your answer here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question 2:**  \n",
        "How does LIME generate local explanations for a model's prediction, and why is this approach considered model-agnostic?  \n",
        "*Your Answer:*  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> *(Type your answer here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question 3:**  \n",
        "Discuss the trade-offs between model complexity and interpretability. How do these trade-offs impact both the performance of a model and its deployment in real-world, sensitive applications?\n",
        "*Your Answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> *(Type your answer here)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Autograder\n",
        "\n",
        "Run this code cell at the end and do not change any code here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir datasets\n",
        "!wget -p https://raw.githubusercontent.com/sprince0031/CS4445-AI-Practice/refs/heads/main/datasets/dog.jpg -O datasets/dog.jpg\n",
        "\n",
        "# ================================\n",
        "# Pytest Tests for Challenge #7: LIME Explainability\n",
        "# ================================\n",
        "\n",
        "import pytest\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "def run_tests_and_accumulate_score():\n",
        "    total_code_points = 6  # Tasks 1-4: 2 + 1 + 1 + 2 = 6 points\n",
        "    score = 0\n",
        "\n",
        "    # Prepare dummy setup for testing:\n",
        "    # Create a dummy image (224 x 224 x 3) as a numpy array.\n",
        "    dummy_image = Image.open(\"datasets/dog.jpg\")\n",
        "    dummy_image = np.array(dummy_image)\n",
        "    \n",
        "    # Dummy model for LIME explanation tests (for Task 1, 2, 3)\n",
        "    class DummyModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(DummyModel, self).__init__()\n",
        "            self.flatten = nn.Flatten()\n",
        "            self.fc = nn.Linear(224*224*3, 2)  # Assume 2 classes for simplicity.\n",
        "        def forward(self, x):\n",
        "            x = self.flatten(x)\n",
        "            return torch.softmax(self.fc(x), dim=1)\n",
        "    \n",
        "    dummy_model = DummyModel()\n",
        "    \n",
        "    # ------------------------------\n",
        "    # Task 1: get_lime_explanation (2 points)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        explanation = get_lime_explanation(dummy_model, dummy_image, top_labels=2, num_samples=100)\n",
        "        assert explanation is not None, \"get_lime_explanation() returned None.\"\n",
        "        # Check for at least one expected method (as_list or get_image_and_mask).\n",
        "        has_method = hasattr(explanation, \"as_list\") or hasattr(explanation, \"get_image_and_mask\")\n",
        "        assert has_method, \"Explanation object lacks expected methods.\"\n",
        "        score += 2\n",
        "        print(\"Task 1 (get_lime_explanation): Passed (2 points)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Task 1 (get_lime_explanation): Failed -\", e)\n",
        "    \n",
        "    # ------------------------------\n",
        "    # Task 2: display_lime_explanation (1 point)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        expl_img, mask = display_lime_explanation(explanation, dummy_image, positive_only=True, num_features=5)\n",
        "        assert expl_img is not None, \"display_lime_explanation() returned None for explanation image.\"\n",
        "        assert mask is not None, \"display_lime_explanation() returned None for mask.\"\n",
        "        assert isinstance(expl_img, np.ndarray), \"Explanation image should be a numpy array.\"\n",
        "        assert isinstance(mask, np.ndarray), \"Mask should be a numpy array.\"\n",
        "        score += 1\n",
        "        print(\"Task 2 (display_lime_explanation): Passed (1 point)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Task 2 (display_lime_explanation): Failed -\", e)\n",
        "    \n",
        "    # ------------------------------\n",
        "    # Task 3: extract_feature_importance (1 point)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        feature_list = extract_feature_importance(explanation)\n",
        "        assert isinstance(feature_list, list), \"extract_feature_importance() should return a list.\"\n",
        "        if feature_list:\n",
        "            first_item = feature_list[0]\n",
        "            assert isinstance(first_item, tuple) and len(first_item) == 2, \"Each item should be a tuple (feature, importance).\"\n",
        "        score += 1\n",
        "        print(\"Task 3 (extract_feature_importance): Passed (1 point)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Task 3 (extract_feature_importance): Failed -\", e)\n",
        "    \n",
        "    # ------------------------------\n",
        "    # Task 4: Pretrained ResNet LIME Explanations (2 points)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        explanations = get_resnet_lime_explanations(dummy_image)\n",
        "        assert isinstance(explanations, dict), \"get_resnet_lime_explanations() should return a dictionary.\"\n",
        "        # Expect 5 keys corresponding to top 5 classes.\n",
        "        assert len(explanations) == 5, \"Expected explanations for top 5 classes.\"\n",
        "        print('top 5 label predictions:')\n",
        "        for i, (label, (expl_img, mask)) in enumerate(explanations.items()):\n",
        "            assert isinstance(expl_img, np.ndarray), \"Explanation image should be a numpy array.\"\n",
        "            assert isinstance(mask, np.ndarray), \"Mask should be a numpy array.\"\n",
        "            print(f'{i+1}. {label}')\n",
        "            # plt.subplot(1, 5, i+1)\n",
        "        expl_img, mask = next(iter(explanations.values()))\n",
        "        visualiseExplanation(expl_img, mask)\n",
        "        score += 2\n",
        "        print(\"Task 4 (ResNet LIME Explanations): Passed (2 points)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Task 4 (ResNet LIME Explanations): Failed -\", e)\n",
        "    \n",
        "    print(f\"Total Code Score: {score} / {total_code_points}\")\n",
        "    \n",
        "    # Reflection questions are graded manually.\n",
        "    print(\"Reflection Questions: 3 points (graded manually)\")\n",
        "    \n",
        "# Run the autograder.\n",
        "run_tests_and_accumulate_score()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
