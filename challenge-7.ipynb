{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ISE-CS4445-AI/challenge-7-tomjoyce1/blob/main/challenge-7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSNohoRf9Wum"
      },
      "source": [
        "# Challenge #7: Interpretability and explainable ML\n",
        "\n",
        "In this assignment, you will explore explainability using LIME on image classification. Your tasks are:\n",
        "\n",
        "1. **get_lime_explanation: (3 points)**  \n",
        "   Given a pretrained image classifier and an input image, generate a LIME explanation object.\n",
        "\n",
        "2. **display_lime_explanation: (1 point)**  \n",
        "   From the explanation object, extract and return a visualization (image and mask overlay) that highlights important superpixels.\n",
        "\n",
        "3. **extract_feature_importance: (1 point)**  \n",
        "   Extract a list of important feature (superpixel) contributions from the explanation object, sorted by importance.\n",
        "\n",
        "4. **Task 4:** Apply a pretrained ResNet model on an input image and use LIME to generate and display explanations for the top 5 predicted classes.\n",
        "\n",
        "After coding, answer three brief reflection questions on explainability methods.\n",
        "\n",
        "*Total points: 9 (6 points for code tasks and 3 points for reflection questions).*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzph8YNht_I_"
      },
      "source": [
        "## Background on LIME\n",
        "\n",
        "LIME (Local Interpretable Model-agnostic Explanations) is a popular method for explaining predictions of any classifier. For image classification, LIME works by:\n",
        "- Perturbing the input image by turning superpixels on/off.\n",
        "- Evaluating how these perturbations affect the prediction.\n",
        "- Fitting a local, interpretable linear model to approximate the classifier's behavior near the instance.\n",
        "\n",
        "The result is an explanation object that can produce:\n",
        "- A list of feature contributions.\n",
        "- A visualization (image with a mask overlay) highlighting which superpixels had the greatest influence on the prediction.\n",
        "\n",
        "**Additional resources:**  \n",
        "[Official LIME blog post](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)  \n",
        "[Tutorial notebooks on their official GitHub repository](https://github.com/marcotcr/lime/tree/master/doc/notebooks)  \n",
        "[General article reading about explainable machine learning | Medium](https://medium.com/michelle-and-ryan-explain-ml/explainable-and-interpretable-machine-learning-7e7c28bba4f2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UM1fVyy9Wun"
      },
      "source": [
        "## Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTWoSED5t_JC",
        "outputId": "d2874778-a511-4046-f2ff-ab35279bb812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.11/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "LfptRzGQ9Wuo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9d3a91-8b9f-46bd-802d-aacc975a7208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.5.1+cu124\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from lime import lime_image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import cv2\n",
        "import json\n",
        "from torchvision import models, transforms\n",
        "\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGhzcybk9Wuo"
      },
      "source": [
        "## Task 1: Get LIME Explanation <font color='green'>(3 points)</font>\n",
        "\n",
        "Generate and return a LIME explanation object for the given image and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "GNF9J7iy9Wuo"
      },
      "outputs": [],
      "source": [
        "def display_lime_explanation(explanation, image: np.ndarray, positive_only: bool = True, num_features: int = 5):\n",
        "\n",
        "    explanation_image, mask = explanation.get_image_and_mask(\n",
        "        label=explanation.top_labels[0],   # Changed 'top_labels' to 'label' and assigned the value of the top predicted label\n",
        "        positive_only=positive_only,\n",
        "        num_features=num_features\n",
        "    )\n",
        "\n",
        "    return explanation_image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJQ2coP99Wuo"
      },
      "source": [
        "## Task 2: Display LIME Explanation <font color='green'>(1 point)</font>\n",
        "\n",
        "Implement a function that extracts and returns the visualization of the LIME explanation. This function should use the explanation object's method (such as `get_image_and_mask`) to generate an image with an overlay mask that highlights the most important superpixels.\n",
        "\n",
        "The output should be a tuple: (explanation_image, mask), which you can then display using matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "F4db54aV9Wup"
      },
      "outputs": [],
      "source": [
        "def visualiseExplanation(explanation_image, mask):\n",
        "    \"\"\"\n",
        "    Visualize the LIME explanation by overlaying the mask on the explanation image.\n",
        "\n",
        "    Parameters:\n",
        "        explanation_image (np.ndarray): The image after LIME processing.\n",
        "        mask (np.ndarray): The mask that highlights important superpixels.\n",
        "\n",
        "    Returns:\n",
        "        None: Displays the visualization.\n",
        "    \"\"\"\n",
        "    img_boundry = mark_boundaries(explanation_image/255.0, mask)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img_boundry)\n",
        "\n",
        "def display_lime_explanation(explanation, image: np.ndarray, positive_only: bool = True, num_features: int = 5):\n",
        "\n",
        "    explanation_image, mask = explanation.get_image_and_mask(\n",
        "        top_labels=0,\n",
        "        positive_only=positive_only,\n",
        "        num_features=num_features\n",
        "    )\n",
        "\n",
        "    return explanation_image, mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS4VlLMet_JM"
      },
      "source": [
        "## Task 3: Extract Feature Importance <font color='green'>(1 point)</font>\n",
        "\n",
        "Implement a function that extracts a sorted list of feature (superpixel) contributions from the LIME explanation object. The function should return a list of tuples (feature_index, importance) sorted in descending order by importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "l4_wowyh9Wup"
      },
      "outputs": [],
      "source": [
        "def extract_feature_importance(explanation) -> list:\n",
        "\n",
        "    feature_importances = explanation.local_exp[explanation.top_labels[0]]\n",
        "\n",
        "    sorted_feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return sorted_feature_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMQwPz0dt_JN"
      },
      "source": [
        "## Task 4: Top 5 explanations from a pretrained ResNet model <font color='green'>(2 points)</font>\n",
        "\n",
        "Use a pretrained ResNet model to predict the image classes and generate LIME explanations for the top 5 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwN2_j1pt_JN",
        "outputId": "09258a61-4d00-48cd-92c5-00b5bdd0710e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-07 14:09:59--  https://github.com/marcotcr/lime/blob/master/doc/notebooks/data/imagenet_class_index.json?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/marcotcr/lime/raw/refs/heads/master/doc/notebooks/data/imagenet_class_index.json [following]\n",
            "--2025-03-07 14:09:59--  https://github.com/marcotcr/lime/raw/refs/heads/master/doc/notebooks/data/imagenet_class_index.json\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/marcotcr/lime/refs/heads/master/doc/notebooks/data/imagenet_class_index.json [following]\n",
            "--2025-03-07 14:09:59--  https://raw.githubusercontent.com/marcotcr/lime/refs/heads/master/doc/notebooks/data/imagenet_class_index.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35363 (35K) [text/plain]\n",
            "Saving to: ‘imagenet_class_index.json’\n",
            "\n",
            "imagenet_class_inde 100%[===================>]  34.53K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-03-07 14:09:59 (5.44 MB/s) - ‘imagenet_class_index.json’ saved [35363/35363]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download ImageNet class label mappings\n",
        "!wget https://github.com/marcotcr/lime/blob/master/doc/notebooks/data/imagenet_class_index.json?raw=true -O imagenet_class_index.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "R3ItPDStt_JO"
      },
      "outputs": [],
      "source": [
        "def get_resnet_lime_explanations(image: np.ndarray):\n",
        "    imagenet_labels = json.load(open(\"imagenet_class_index.json\"))\n",
        "    imagenet_labels = {int(key): value[1] for key, value in imagenet_labels.items()}\n",
        "\n",
        "    # pretrained ResNet18 model\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.eval()\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    image_tensor = preprocess(image).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        top5_probabilities, top5_labels = torch.topk(probabilities, 5)\n",
        "\n",
        "    explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "    explanations = {}\n",
        "\n",
        "    for i in range(5):\n",
        "        label = top5_labels[0][i].item()\n",
        "        class_name = imagenet_labels.get(label, str(label))\n",
        "\n",
        "        def predict_fn(images):\n",
        "            transformed_images = torch.stack([preprocess(img) for img in images])\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(transformed_images)\n",
        "                probs = torch.nn.functional.softmax(outputs, dim=1).numpy()\n",
        "\n",
        "            return probs\n",
        "\n",
        "        explanation = explainer.explain_instance(\n",
        "            image,\n",
        "            predict_fn,\n",
        "            top_labels=5,\n",
        "            num_samples=1000\n",
        "        )\n",
        "\n",
        "        explanation_image, mask = explanation.get_image_and_mask(label, positive_only=True, num_features=5)\n",
        "\n",
        "        explanations[class_name] = (explanation_image, mask)\n",
        "\n",
        "    return explanations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvT1-52Ft_JO"
      },
      "source": [
        "## Reflection Questions (answer in brief)  <font color='green'>(1 point each)</font>\n",
        "\n",
        "**Question 1:**  \n",
        "What are the main advantages of using LIME for explaining image classification models?  \n",
        "*Your Answer:*  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lal1hGst_JO"
      },
      "source": [
        "> *(LIME is model agnostic, so it can be applied to any image classification model. It generates highlighted superpixels for the regions that contribute most to the prediction, meaning it's easy for humans to understand/interpret, as the important sections are highlighted. This can help detect bias.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3HX5B83t_JP"
      },
      "source": [
        "**Question 2:**  \n",
        "How does LIME generate local explanations for a model's prediction, and why is this approach considered model-agnostic?  \n",
        "*Your Answer:*  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDN3Q3E1t_JP"
      },
      "source": [
        "> *(It is model agnostic because it doesn't need to know about the internal workings of the model, but only have access to the model's input and output. It generates local explanations by perturbing the input image, feeding the perturbed image to the original model, fitting a simple model to the predictions, and then uses the weights of this local model to determine the importance of each superpixel.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye4M0xemt_JP"
      },
      "source": [
        "**Question 3:**  \n",
        "Discuss the trade-offs between model complexity and interpretability. How do these trade-offs impact both the performance of a model and its deployment in real-world, sensitive applications?\n",
        "*Your Answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF0tGdXlt_JQ"
      },
      "source": [
        "> *(Generally, more complex models achieve higher accuracy and performance on complex tasks compared to simpler models, as they have more parameters and intricate internal structures. This comes at the cost of reduced interpretability. Simpler models are less accurate but more transparent. In the real world, high performance is important e.g - medical diagnosis, but understanding how the model decides is also crucial, so a less complex model may be chosen if it is more interpretable.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBvbrefEt_JQ"
      },
      "source": [
        "---\n",
        "### Autograder\n",
        "\n",
        "Run this code cell at the end and do not change any code here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535,
          "referenced_widgets": [
            "c6f80b88a2b048f4ae7146cafa0c7234",
            "8ec202c6fe494328b5b9683412ec9b70",
            "17fab12bb2a54150a21fb1e3886cdaa1",
            "a93468d68b2f4289ba874298b0ab4d50",
            "9f32cb7a1e5c40d6ac45d9d7fde6be70",
            "320fb936c7c94e3c9fa7c054b1a4f2e1",
            "81b3dd0a122d4a1d82568e18d57903e6",
            "2e2b0fa6728d4061b1893dc2c94adccb",
            "c3cef084f20d44cbb3f084c097cb5c7c",
            "7390c79aa30d408fab3854072fc06fe6",
            "403397b86d0747f28bb8e6b1832ced7c",
            "388b3ab6cd6a4c9e85f793a5bdea14ef",
            "cf559dfbb2434edc8d69e7b7a0b59de1",
            "9325d827f07341dfb40d3c85f1555263",
            "57a138e4c7494e93bb438989ede4686e",
            "d2448249033d4ca09e2f28e02e956914",
            "925fccfd8644449084ab6fefa9105d07",
            "701121a1c01841c98a896d2f49bac70a",
            "2aca3366252e44b4a0da2862687f7b46",
            "4e43d7fac4604d18af408cb4344ffc48",
            "538590c11ccc493dac92cc825a9a05a3",
            "f31b5bb6f03f40b9a457b104197062e3"
          ]
        },
        "id": "cv2401YYt_JQ",
        "outputId": "6d9d5457-5f88-48f3-9f53-9bb55e212fe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘datasets’: File exists\n",
            "WARNING: combining -O with -r or -p will mean that all downloaded content\n",
            "will be placed in the single file you specified.\n",
            "\n",
            "--2025-03-07 14:12:04--  https://raw.githubusercontent.com/sprince0031/CS4445-AI-Practice/refs/heads/main/datasets/dog.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47018 (46K) [image/jpeg]\n",
            "Saving to: ‘datasets/dog.jpg’\n",
            "\n",
            "datasets/dog.jpg    100%[===================>]  45.92K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-03-07 14:12:04 (6.28 MB/s) - ‘datasets/dog.jpg’ saved [47018/47018]\n",
            "\n",
            "FINISHED --2025-03-07 14:12:04--\n",
            "Total wall clock time: 0.2s\n",
            "Downloaded: 1 files, 46K in 0.007s (6.28 MB/s)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6f80b88a2b048f4ae7146cafa0c7234"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1 (get_lime_explanation): Passed (2 points)\n",
            "Task 2 (display_lime_explanation): Passed (1 point)\n",
            "Task 3 (extract_feature_importance): Passed (1 point)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "388b3ab6cd6a4c9e85f793a5bdea14ef"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!mkdir datasets\n",
        "!wget -p https://raw.githubusercontent.com/sprince0031/CS4445-AI-Practice/refs/heads/main/datasets/dog.jpg -O datasets/dog.jpg\n",
        "\n",
        "# ================================\n",
        "# Pytest Tests for Challenge #7: LIME Explainability\n",
        "# ================================\n",
        "\n",
        "import pytest\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "def run_tests_and_accumulate_score():\n",
        "    total_code_points = 6  # Tasks 1-4: 2 + 1 + 1 + 2 = 6 points\n",
        "    score = 0\n",
        "\n",
        "    # Prepare dummy setup for testing:\n",
        "    # Create a dummy image (224 x 224 x 3) as a numpy array.\n",
        "    dummy_image = Image.open(\"datasets/dog.jpg\")\n",
        "    dummy_image = np.array(dummy_image)\n",
        "\n",
        "    # Dummy model for LIME explanation tests (for Task 1, 2, 3)\n",
        "    class DummyModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(DummyModel, self).__init__()\n",
        "            self.flatten = nn.Flatten()\n",
        "            self.fc = nn.Linear(224*224*3, 2)  # Assume 2 classes for simplicity.\n",
        "        def forward(self, x):\n",
        "            x = self.flatten(x)\n",
        "            return torch.softmax(self.fc(x), dim=1)\n",
        "\n",
        "    dummy_model = DummyModel()\n",
        "\n",
        "    # ------------------------------\n",
        "    # Task 1: get_lime_explanation (2 points)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        explanation = get_lime_explanation(dummy_model, dummy_image, top_labels=2, num_samples=100)\n",
        "        assert explanation is not None, \"get_lime_explanation() returned None.\"\n",
        "        # Check for at least one expected method (as_list or get_image_and_mask).\n",
        "        has_method = hasattr(explanation, \"as_list\") or hasattr(explanation, \"get_image_and_mask\")\n",
        "        assert has_method, \"Explanation object lacks expected methods.\"\n",
        "        score += 2\n",
        "        print(\"Task 1 (get_lime_explanation): Passed (2 points)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Task 1 (get_lime_explanation): Failed -\", e)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Task 2: display_lime_explanation (1 point)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        expl_img, mask = display_lime_explanation(explanation, dummy_image, positive_only=True, num_features=5)\n",
        "        assert expl_img is not None, \"display_lime_explanation() returned None for explanation image.\"\n",
        "        assert mask is not None, \"display_lime_explanation() returned None for mask.\"\n",
        "        assert isinstance(expl_img, np.ndarray), \"Explanation image should be a numpy array.\"\n",
        "        assert isinstance(mask, np.ndarray), \"Mask should be a numpy array.\"\n",
        "        score += 1\n",
        "        print(\"Task 2 (display_lime_explanation): Passed (1 point)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Task 2 (display_lime_explanation): Failed -\", e)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Task 3: extract_feature_importance (1 point)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        feature_list = extract_feature_importance(explanation)\n",
        "        assert isinstance(feature_list, list), \"extract_feature_importance() should return a list.\"\n",
        "        if feature_list:\n",
        "            first_item = feature_list[0]\n",
        "            assert isinstance(first_item, tuple) and len(first_item) == 2, \"Each item should be a tuple (feature, importance).\"\n",
        "        score += 1\n",
        "        print(\"Task 3 (extract_feature_importance): Passed (1 point)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Task 3 (extract_feature_importance): Failed -\", e)\n",
        "\n",
        "    # ------------------------------\n",
        "    # Task 4: Pretrained ResNet LIME Explanations (2 points)\n",
        "    # ------------------------------\n",
        "    try:\n",
        "        explanations = get_resnet_lime_explanations(dummy_image)\n",
        "        assert isinstance(explanations, dict), \"get_resnet_lime_explanations() should return a dictionary.\"\n",
        "        # Expect 5 keys corresponding to top 5 classes.\n",
        "        assert len(explanations) == 5, \"Expected explanations for top 5 classes.\"\n",
        "        print('top 5 label predictions:')\n",
        "        for i, (label, (expl_img, mask)) in enumerate(explanations.items()):\n",
        "            assert isinstance(expl_img, np.ndarray), \"Explanation image should be a numpy array.\"\n",
        "            assert isinstance(mask, np.ndarray), \"Mask should be a numpy array.\"\n",
        "            print(f'{i+1}. {label}')\n",
        "            # plt.subplot(1, 5, i+1)\n",
        "        expl_img, mask = next(iter(explanations.values()))\n",
        "        visualiseExplanation(expl_img, mask)\n",
        "        score += 2\n",
        "        print(\"Task 4 (ResNet LIME Explanations): Passed (2 points)\")\n",
        "    except AssertionError as e:\n",
        "        print(\"Task 4 (ResNet LIME Explanations): Failed -\", e)\n",
        "\n",
        "    print(f\"Total Code Score: {score} / {total_code_points}\")\n",
        "\n",
        "    # Reflection questions are graded manually.\n",
        "    print(\"Reflection Questions: 3 points (graded manually)\")\n",
        "\n",
        "# Run the autograder.\n",
        "run_tests_and_accumulate_score()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6f80b88a2b048f4ae7146cafa0c7234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ec202c6fe494328b5b9683412ec9b70",
              "IPY_MODEL_17fab12bb2a54150a21fb1e3886cdaa1",
              "IPY_MODEL_a93468d68b2f4289ba874298b0ab4d50"
            ],
            "layout": "IPY_MODEL_9f32cb7a1e5c40d6ac45d9d7fde6be70"
          }
        },
        "8ec202c6fe494328b5b9683412ec9b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_320fb936c7c94e3c9fa7c054b1a4f2e1",
            "placeholder": "​",
            "style": "IPY_MODEL_81b3dd0a122d4a1d82568e18d57903e6",
            "value": "100%"
          }
        },
        "17fab12bb2a54150a21fb1e3886cdaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e2b0fa6728d4061b1893dc2c94adccb",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3cef084f20d44cbb3f084c097cb5c7c",
            "value": 100
          }
        },
        "a93468d68b2f4289ba874298b0ab4d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7390c79aa30d408fab3854072fc06fe6",
            "placeholder": "​",
            "style": "IPY_MODEL_403397b86d0747f28bb8e6b1832ced7c",
            "value": " 100/100 [00:09&lt;00:00, 11.19it/s]"
          }
        },
        "9f32cb7a1e5c40d6ac45d9d7fde6be70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "320fb936c7c94e3c9fa7c054b1a4f2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b3dd0a122d4a1d82568e18d57903e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e2b0fa6728d4061b1893dc2c94adccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cef084f20d44cbb3f084c097cb5c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7390c79aa30d408fab3854072fc06fe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403397b86d0747f28bb8e6b1832ced7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "388b3ab6cd6a4c9e85f793a5bdea14ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf559dfbb2434edc8d69e7b7a0b59de1",
              "IPY_MODEL_9325d827f07341dfb40d3c85f1555263",
              "IPY_MODEL_57a138e4c7494e93bb438989ede4686e"
            ],
            "layout": "IPY_MODEL_d2448249033d4ca09e2f28e02e956914"
          }
        },
        "cf559dfbb2434edc8d69e7b7a0b59de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_925fccfd8644449084ab6fefa9105d07",
            "placeholder": "​",
            "style": "IPY_MODEL_701121a1c01841c98a896d2f49bac70a",
            "value": " 54%"
          }
        },
        "9325d827f07341dfb40d3c85f1555263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aca3366252e44b4a0da2862687f7b46",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e43d7fac4604d18af408cb4344ffc48",
            "value": 540
          }
        },
        "57a138e4c7494e93bb438989ede4686e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538590c11ccc493dac92cc825a9a05a3",
            "placeholder": "​",
            "style": "IPY_MODEL_f31b5bb6f03f40b9a457b104197062e3",
            "value": " 540/1000 [01:17&lt;01:18,  5.87it/s]"
          }
        },
        "d2448249033d4ca09e2f28e02e956914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "925fccfd8644449084ab6fefa9105d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "701121a1c01841c98a896d2f49bac70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aca3366252e44b4a0da2862687f7b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e43d7fac4604d18af408cb4344ffc48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "538590c11ccc493dac92cc825a9a05a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f31b5bb6f03f40b9a457b104197062e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}